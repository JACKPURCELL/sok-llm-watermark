nohup: ignoring input
2024-01-11 01:37:00.021695: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-11 01:37:00.072913: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-01-11 01:37:00.072972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-01-11 01:37:00.074211: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-11 01:37:00.081795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-11 01:37:01.225817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Currently logged in as: ljcpro (alps-lab-sok). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /home/jkl6486/sok-llm-watermark/wandb/run-20240111_013705-ld0o01v9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gen-c4-xuandong23b-llama-temp0.4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/alps-lab-sok/lm-watermarking
wandb: üöÄ View run at https://wandb.ai/alps-lab-sok/lm-watermarking/runs/ld0o01v9
No limit_indices specified, pulling all examples from the dataset.
Output dir for this run: runs/xuandong23b/c4/llama/gen-0.4
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.84s/it]
  0%|          | 0/1000 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Traceback (most recent call last):
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/generation_pipeline.py", line 871, in <module>
    main(args)
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/generation_pipeline.py", line 404, in main
    ex = next(ds_iterator)
         ^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/datasets/iterable_dataset.py", line 981, in __iter__
    for key, example in ex_iterable:
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/datasets/iterable_dataset.py", line 477, in __iter__
    transformed_batch.update(self.function(*function_args, **self.fn_kwargs))
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/utils/generation.py", line 494, in generate
    output_with_watermark = generate_with_watermark(input_ids=input_ids)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/transformers/generation/utils.py", line 1764, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/transformers/generation/utils.py", line 2897, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
wandb: üöÄ View run gen-c4-xuandong23b-llama-temp0.4 at: https://wandb.ai/alps-lab-sok/lm-watermarking/runs/ld0o01v9
wandb: Ô∏è‚ö° View job at https://wandb.ai/alps-lab-sok/lm-watermarking/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMzQ2NTIxNg==/version_details/v38
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240111_013705-ld0o01v9/logs
2024-01-11 01:37:57.370149: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-11 01:37:57.404100: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-01-11 01:37:57.404153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-01-11 01:37:57.405002: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-11 01:37:57.410066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-11 01:37:58.190883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Currently logged in as: ljcpro (alps-lab-sok). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /home/jkl6486/sok-llm-watermark/wandb/run-20240111_013801-4wdo7nzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gen-c4-xuandong23b-llama-temp1.0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/alps-lab-sok/lm-watermarking
wandb: üöÄ View run at https://wandb.ai/alps-lab-sok/lm-watermarking/runs/4wdo7nzw
No limit_indices specified, pulling all examples from the dataset.
Output dir for this run: runs/xuandong23b/c4/llama/gen-1.0
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.53s/it]
  0%|          | 0/1000 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Traceback (most recent call last):
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/generation_pipeline.py", line 871, in <module>
    main(args)
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/generation_pipeline.py", line 404, in main
    ex = next(ds_iterator)
         ^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/datasets/iterable_dataset.py", line 981, in __iter__
    for key, example in ex_iterable:
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/datasets/iterable_dataset.py", line 477, in __iter__
    transformed_batch.update(self.function(*function_args, **self.fn_kwargs))
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/utils/generation.py", line 485, in generate
    output_without_watermark = generate_without_watermark(input_ids=input_ids)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/transformers/generation/utils.py", line 1764, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/transformers/generation/utils.py", line 2897, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
wandb: - 0.008 MB of 0.008 MB uploadedwandb: \ 0.008 MB of 0.008 MB uploadedwandb: üöÄ View run gen-c4-xuandong23b-llama-temp1.0 at: https://wandb.ai/alps-lab-sok/lm-watermarking/runs/4wdo7nzw
wandb: Ô∏è‚ö° View job at https://wandb.ai/alps-lab-sok/lm-watermarking/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMzQ2NTIxNg==/version_details/v38
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240111_013801-4wdo7nzw/logs
2024-01-11 01:38:42.525745: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-11 01:38:42.580546: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-01-11 01:38:42.580641: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-01-11 01:38:42.582696: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-11 01:38:42.594967: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-11 01:38:44.070775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Currently logged in as: ljcpro (alps-lab-sok). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /home/jkl6486/sok-llm-watermark/wandb/run-20240111_013849-l0xmojtp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gen-c4-xuandong23b-opt-temp1.0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/alps-lab-sok/lm-watermarking
wandb: üöÄ View run at https://wandb.ai/alps-lab-sok/lm-watermarking/runs/l0xmojtp
No limit_indices specified, pulling all examples from the dataset.
Output dir for this run: runs/xuandong23b/c4/opt/gen-1.0
  0%|          | 0/1000 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1000 [01:05<18:12:48, 65.63s/it]  0%|          | 5/1000 [01:56<5:41:08, 20.57s/it]   1%|          | 9/1000 [02:57<4:51:31, 17.65s/it]  1%|‚ñè         | 13/1000 [03:59<4:34:46, 16.70s/it]  2%|‚ñè         | 17/1000 [04:57<4:19:47, 15.86s/it]  2%|‚ñè         | 21/1000 [05:51<4:05:32, 15.05s/it]  2%|‚ñé         | 25/1000 [06:45<3:56:21, 14.54s/it]  3%|‚ñé         | 29/1000 [07:45<3:56:48, 14.63s/it]  3%|‚ñé         | 33/1000 [08:43<3:56:10, 14.65s/it]  4%|‚ñé         | 37/1000 [09:36<3:47:44, 14.19s/it]  4%|‚ñç         | 41/1000 [10:28<3:40:59, 13.83s/it]  4%|‚ñç         | 45/1000 [11:29<3:47:07, 14.27s/it]  5%|‚ñç         | 49/1000 [12:28<3:48:33, 14.42s/it]  5%|‚ñå         | 53/1000 [13:19<3:39:42, 13.92s/it]  6%|‚ñå         | 57/1000 [13:49<3:07:39, 11.94s/it]  6%|‚ñå         | 61/1000 [14:29<2:58:16, 11.39s/it]  6%|‚ñã         | 65/1000 [15:12<2:54:10, 11.18s/it]  7%|‚ñã         | 69/1000 [15:46<2:41:00, 10.38s/it]  7%|‚ñã         | 73/1000 [16:32<2:45:57, 10.74s/it]  8%|‚ñä         | 77/1000 [17:08<2:36:08, 10.15s/it]  8%|‚ñä         | 81/1000 [18:03<2:52:06, 11.24s/it]  8%|‚ñä         | 85/1000 [19:00<3:05:38, 12.17s/it]  9%|‚ñâ         | 89/1000 [19:54<3:11:15, 12.60s/it]  9%|‚ñâ         | 93/1000 [21:01<3:28:28, 13.79s/it] 10%|‚ñâ         | 97/1000 [21:54<3:24:59, 13.62s/it] 10%|‚ñà         | 101/1000 [22:58<3:34:45, 14.33s/it] 10%|‚ñà         | 105/1000 [23:54<3:32:12, 14.23s/it] 11%|‚ñà         | 109/1000 [24:47<3:27:22, 13.96s/it] 11%|‚ñà‚ñè        | 113/1000 [25:43<3:27:10, 14.01s/it] 12%|‚ñà‚ñè        | 117/1000 [26:50<3:37:52, 14.80s/it] 12%|‚ñà‚ñè        | 121/1000 [27:51<3:38:42, 14.93s/it] 12%|‚ñà‚ñé        | 125/1000 [28:51<3:38:24, 14.98s/it] 13%|‚ñà‚ñé        | 129/1000 [29:56<3:42:36, 15.33s/it] 13%|‚ñà‚ñé        | 133/1000 [30:45<3:28:17, 14.41s/it] 14%|‚ñà‚ñé        | 137/1000 [31:25<3:07:59, 13.07s/it] 14%|‚ñà‚ñç        | 141/1000 [32:15<3:04:31, 12.89s/it] 14%|‚ñà‚ñç        | 145/1000 [33:13<3:11:07, 13.41s/it] 15%|‚ñà‚ñç        | 149/1000 [34:18<3:22:01, 14.24s/it] 15%|‚ñà‚ñå        | 153/1000 [35:15<3:21:30, 14.27s/it] 16%|‚ñà‚ñå        | 157/1000 [36:20<3:28:31, 14.84s/it] 16%|‚ñà‚ñå        | 161/1000 [37:15<3:22:35, 14.49s/it] 16%|‚ñà‚ñã        | 165/1000 [38:22<3:31:40, 15.21s/it] 17%|‚ñà‚ñã        | 169/1000 [39:18<3:25:06, 14.81s/it] 17%|‚ñà‚ñã        | 173/1000 [40:15<3:21:46, 14.64s/it] 18%|‚ñà‚ñä        | 177/1000 [41:11<3:18:50, 14.50s/it] 18%|‚ñà‚ñä        | 181/1000 [42:11<3:19:52, 14.64s/it] 18%|‚ñà‚ñä        | 185/1000 [43:05<3:14:18, 14.30s/it] 19%|‚ñà‚ñâ        | 189/1000 [44:05<3:15:25, 14.46s/it] 19%|‚ñà‚ñâ        | 193/1000 [45:08<3:19:38, 14.84s/it] 20%|‚ñà‚ñâ        | 197/1000 [45:59<3:11:03, 14.28s/it] 20%|‚ñà‚ñà        | 201/1000 [46:26<2:40:12, 12.03s/it] 20%|‚ñà‚ñà        | 205/1000 [47:14<2:39:04, 12.01s/it] 21%|‚ñà‚ñà        | 209/1000 [48:19<2:55:02, 13.28s/it] 21%|‚ñà‚ñà‚ñè       | 213/1000 [49:20<3:01:24, 13.83s/it] 22%|‚ñà‚ñà‚ñè       | 217/1000 [50:13<2:58:54, 13.71s/it] 22%|‚ñà‚ñà‚ñè       | 221/1000 [51:07<2:56:31, 13.60s/it] 22%|‚ñà‚ñà‚ñé       | 225/1000 [52:00<2:54:18, 13.49s/it] 23%|‚ñà‚ñà‚ñé       | 229/1000 [53:02<3:01:28, 14.12s/it] 23%|‚ñà‚ñà‚ñé       | 233/1000 [54:00<3:01:47, 14.22s/it] 24%|‚ñà‚ñà‚ñé       | 237/1000 [55:02<3:06:01, 14.63s/it] 24%|‚ñà‚ñà‚ñç       | 241/1000 [56:01<3:05:32, 14.67s/it] 24%|‚ñà‚ñà‚ñç       | 245/1000 [57:00<3:04:23, 14.65s/it] 25%|‚ñà‚ñà‚ñç       | 249/1000 [57:55<3:00:01, 14.38s/it] 25%|‚ñà‚ñà‚ñå       | 253/1000 [58:46<2:53:01, 13.90s/it] 26%|‚ñà‚ñà‚ñå       | 257/1000 [59:41<2:51:26, 13.84s/it] 26%|‚ñà‚ñà‚ñå       | 261/1000 [1:00:37<2:50:55, 13.88s/it] 26%|‚ñà‚ñà‚ñã       | 265/1000 [1:01:25<2:43:53, 13.38s/it] 27%|‚ñà‚ñà‚ñã       | 269/1000 [1:02:17<2:40:54, 13.21s/it] 27%|‚ñà‚ñà‚ñã       | 273/1000 [1:03:02<2:33:15, 12.65s/it] 28%|‚ñà‚ñà‚ñä       | 277/1000 [1:03:56<2:35:32, 12.91s/it] 28%|‚ñà‚ñà‚ñä       | 281/1000 [1:04:45<2:32:03, 12.69s/it] 28%|‚ñà‚ñà‚ñä       | 285/1000 [1:05:40<2:35:22, 13.04s/it] 29%|‚ñà‚ñà‚ñâ       | 289/1000 [1:06:35<2:36:52, 13.24s/it] 29%|‚ñà‚ñà‚ñâ       | 293/1000 [1:07:04<2:15:10, 11.47s/it] 30%|‚ñà‚ñà‚ñâ       | 297/1000 [1:07:43<2:07:34, 10.89s/it] 30%|‚ñà‚ñà‚ñà       | 301/1000 [1:08:34<2:13:27, 11.46s/it] 30%|‚ñà‚ñà‚ñà       | 305/1000 [1:09:29<2:20:58, 12.17s/it] 31%|‚ñà‚ñà‚ñà       | 309/1000 [1:10:23<2:25:00, 12.59s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 313/1000 [1:11:19<2:28:42, 12.99s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 317/1000 [1:11:57<2:16:06, 11.96s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 321/1000 [1:12:37<2:08:16, 11.34s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 325/1000 [1:13:09<1:56:34, 10.36s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 329/1000 [1:14:01<2:04:17, 11.11s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 333/1000 [1:14:51<2:08:17, 11.54s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 337/1000 [1:15:22<1:55:21, 10.44s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 341/1000 [1:15:56<1:47:47,  9.81s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 345/1000 [1:16:11<1:27:46,  8.04s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 349/1000 [1:16:34<1:19:59,  7.37s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 353/1000 [1:17:07<1:21:48,  7.59s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 357/1000 [1:17:55<1:35:51,  8.94s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 361/1000 [1:18:40<1:42:32,  9.63s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 365/1000 [1:19:08<1:33:30,  8.84s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 369/1000 [1:19:24<1:17:25,  7.36s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 373/1000 [1:20:01<1:22:45,  7.92s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 377/1000 [1:20:25<1:16:28,  7.37s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 381/1000 [1:21:20<1:35:24,  9.25s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 385/1000 [1:22:16<1:49:53, 10.72s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 389/1000 [1:23:17<2:02:40, 12.05s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 393/1000 [1:24:01<1:58:42, 11.73s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 397/1000 [1:24:38<1:50:19, 10.98s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 401/1000 [1:25:28<1:54:23, 11.46s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 405/1000 [1:26:19<1:57:29, 11.85s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 409/1000 [1:27:18<2:05:15, 12.72s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 413/1000 [1:28:09<2:04:47, 12.76s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 417/1000 [1:29:00<2:03:43, 12.73s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 421/1000 [1:29:54<2:05:14, 12.98s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 425/1000 [1:30:47<2:05:00, 13.04s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 429/1000 [1:31:43<2:07:10, 13.36s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 433/1000 [1:32:46<2:13:02, 14.08s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 437/1000 [1:33:27<2:00:52, 12.88s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 441/1000 [1:33:48<1:38:54, 10.62s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 445/1000 [1:34:10<1:23:56,  9.08s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 449/1000 [1:34:30<1:11:52,  7.83s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 453/1000 [1:35:16<1:21:23,  8.93s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 457/1000 [1:36:09<1:32:36, 10.23s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 461/1000 [1:37:07<1:43:49, 11.56s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 465/1000 [1:38:01<1:47:43, 12.08s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 469/1000 [1:38:46<1:45:04, 11.87s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 473/1000 [1:39:32<1:43:06, 11.74s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 477/1000 [1:40:30<1:49:47, 12.60s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 481/1000 [1:41:26<1:52:32, 13.01s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 485/1000 [1:42:19<1:52:24, 13.10s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 489/1000 [1:43:02<1:45:10, 12.35s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 493/1000 [1:43:56<1:47:09, 12.68s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 497/1000 [1:44:42<1:43:36, 12.36s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 501/1000 [1:45:34<1:44:22, 12.55s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 505/1000 [1:46:23<1:42:39, 12.44s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 509/1000 [1:47:13<1:42:04, 12.47s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 513/1000 [1:47:48<1:32:13, 11.36s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 517/1000 [1:48:29<1:28:30, 11.00s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 521/1000 [1:48:58<1:19:20,  9.94s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 525/1000 [1:49:09<1:01:28,  7.77s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 529/1000 [1:49:36<58:09,  7.41s/it]   53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 533/1000 [1:50:09<1:00:08,  7.73s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 537/1000 [1:50:51<1:05:51,  8.54s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 541/1000 [1:51:28<1:06:43,  8.72s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 545/1000 [1:52:03<1:06:35,  8.78s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 549/1000 [1:52:50<1:12:11,  9.61s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 553/1000 [1:53:27<1:11:15,  9.56s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 557/1000 [1:54:15<1:15:56, 10.29s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 561/1000 [1:55:01<1:17:39, 10.61s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 565/1000 [1:55:37<1:13:18, 10.11s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 569/1000 [1:56:13<1:10:36,  9.83s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 573/1000 [1:56:49<1:07:48,  9.53s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 577/1000 [1:57:27<1:07:30,  9.58s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 581/1000 [1:58:09<1:08:29,  9.81s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 585/1000 [1:58:44<1:05:36,  9.49s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 589/1000 [1:59:22<1:05:00,  9.49s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 593/1000 [2:00:03<1:05:52,  9.71s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 597/1000 [2:00:30<59:25,  8.85s/it]   60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 601/1000 [2:00:55<53:38,  8.07s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 605/1000 [2:01:23<51:01,  7.75s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 609/1000 [2:01:57<52:13,  8.02s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 613/1000 [2:02:30<52:10,  8.09s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 617/1000 [2:03:19<59:10,  9.27s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 621/1000 [2:03:59<1:00:03,  9.51s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 625/1000 [2:04:10<46:39,  7.46s/it]   63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 629/1000 [2:04:30<41:57,  6.79s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 633/1000 [2:04:51<38:42,  6.33s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 637/1000 [2:05:13<36:28,  6.03s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 641/1000 [2:05:47<40:39,  6.79s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 645/1000 [2:06:16<40:58,  6.92s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 649/1000 [2:06:50<43:06,  7.37s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 653/1000 [2:07:39<51:03,  8.83s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 657/1000 [2:08:24<54:55,  9.61s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 661/1000 [2:09:09<57:03, 10.10s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 665/1000 [2:09:56<59:07, 10.59s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 669/1000 [2:10:33<56:04, 10.17s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 673/1000 [2:11:11<54:18,  9.97s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 677/1000 [2:11:54<54:46, 10.18s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 681/1000 [2:12:35<54:26, 10.24s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 685/1000 [2:13:08<50:40,  9.65s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 689/1000 [2:14:00<54:56, 10.60s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 693/1000 [2:14:38<52:53, 10.34s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 697/1000 [2:15:11<48:56,  9.69s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 701/1000 [2:15:36<43:08,  8.66s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 705/1000 [2:16:04<40:00,  8.14s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 709/1000 [2:16:27<36:05,  7.44s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 713/1000 [2:16:45<31:10,  6.52s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 717/1000 [2:17:08<29:46,  6.31s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 721/1000 [2:17:42<32:21,  6.96s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 725/1000 [2:18:13<33:10,  7.24s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 729/1000 [2:18:50<35:11,  7.79s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 733/1000 [2:19:32<38:17,  8.60s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 737/1000 [2:20:16<40:55,  9.34s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 741/1000 [2:21:02<43:05,  9.98s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 745/1000 [2:21:28<38:06,  8.97s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 749/1000 [2:21:49<32:38,  7.80s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 753/1000 [2:22:06<27:57,  6.79s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 757/1000 [2:22:55<34:11,  8.44s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 761/1000 [2:23:50<39:45,  9.98s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 765/1000 [2:24:35<40:44, 10.40s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 769/1000 [2:25:18<40:15, 10.46s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 773/1000 [2:25:46<35:37,  9.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 777/1000 [2:26:20<34:14,  9.21s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 781/1000 [2:26:56<33:09,  9.09s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 785/1000 [2:27:33<32:47,  9.15s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 789/1000 [2:28:08<31:47,  9.04s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 793/1000 [2:28:52<33:13,  9.63s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 797/1000 [2:29:38<34:25, 10.18s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 801/1000 [2:30:30<36:39, 11.05s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 805/1000 [2:31:04<33:19, 10.25s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 809/1000 [2:31:34<30:11,  9.48s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 813/1000 [2:32:28<33:07, 10.63s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 817/1000 [2:32:57<29:28,  9.66s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 821/1000 [2:33:43<30:27, 10.21s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 825/1000 [2:34:23<29:29, 10.11s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 829/1000 [2:35:16<31:37, 11.10s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 833/1000 [2:35:56<29:54, 10.75s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 837/1000 [2:36:19<25:06,  9.24s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 841/1000 [2:36:43<21:50,  8.24s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 845/1000 [2:37:16<21:22,  8.28s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 849/1000 [2:38:00<22:57,  9.12s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 853/1000 [2:38:44<23:41,  9.67s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 857/1000 [2:39:28<24:00, 10.07s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 861/1000 [2:40:13<24:11, 10.44s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 865/1000 [2:41:05<25:08, 11.18s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 869/1000 [2:41:47<23:53, 10.94s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 873/1000 [2:42:28<22:45, 10.75s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 877/1000 [2:43:09<21:45, 10.62s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 881/1000 [2:43:52<21:07, 10.65s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 885/1000 [2:44:32<20:00, 10.44s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 889/1000 [2:45:06<18:15,  9.87s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 893/1000 [2:45:47<17:48,  9.98s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 897/1000 [2:46:25<16:52,  9.83s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 901/1000 [2:47:01<15:51,  9.61s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 905/1000 [2:47:35<14:39,  9.26s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 909/1000 [2:48:14<14:18,  9.43s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 913/1000 [2:48:56<14:04,  9.71s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 917/1000 [2:49:48<14:51, 10.73s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 921/1000 [2:50:38<14:45, 11.21s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 925/1000 [2:51:07<12:35, 10.08s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 929/1000 [2:51:42<11:25,  9.65s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 933/1000 [2:52:18<10:34,  9.47s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 937/1000 [2:53:06<10:43, 10.22s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 941/1000 [2:53:49<10:12, 10.38s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 945/1000 [2:54:28<09:18, 10.16s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 949/1000 [2:55:12<08:52, 10.45s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 953/1000 [2:55:51<08:01, 10.25s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 957/1000 [2:56:30<07:13, 10.09s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 961/1000 [2:57:20<07:01, 10.81s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 965/1000 [2:58:00<06:09, 10.55s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 969/1000 [2:58:36<05:13, 10.12s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 973/1000 [2:59:18<04:36, 10.23s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 977/1000 [2:59:59<03:54, 10.19s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 981/1000 [3:00:33<03:04,  9.69s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 985/1000 [3:01:14<02:28,  9.92s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 989/1000 [3:01:51<01:46,  9.70s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 993/1000 [3:02:37<01:11, 10.21s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 997/1000 [3:03:14<00:29,  9.90s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [3:03:14<00:00, 10.99s/it]


























































































































































































































































################################################################################ 
Generation output length check overhead was num rows processed=1000 for 1000 samples. Ratio: 1.0
Writing JSON lines at runs/xuandong23b/c4/opt/gen-1.0/gen_table.jsonl:   0%|          | 0/1000 [00:00<?, ?it/s]Writing JSON lines at runs/xuandong23b/c4/opt/gen-1.0/gen_table.jsonl: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 37198.06it/s]
wandb: - 0.008 MB of 0.008 MB uploadedwandb: \ 0.008 MB of 0.008 MB uploadedwandb: | 0.008 MB of 0.008 MB uploadedwandb: / 0.031 MB of 0.031 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb: generation_overhead_ratio ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:  num_satisfactory_samples ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:            progress_ratio ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   total_generated_samples ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb: generation_overhead_ratio 0.999
wandb:  num_satisfactory_samples 1000
wandb:            progress_ratio 1.0
wandb:   total_generated_samples 1000
wandb: 
wandb: üöÄ View run gen-c4-xuandong23b-opt-temp1.0 at: https://wandb.ai/alps-lab-sok/lm-watermarking/runs/l0xmojtp
wandb: Ô∏è‚ö° View job at https://wandb.ai/alps-lab-sok/lm-watermarking/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMzQ2NTIxNg==/version_details/v37
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240111_013849-l0xmojtp/logs
2024-01-11 04:42:39.065220: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-11 04:42:39.116702: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-01-11 04:42:39.116777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-01-11 04:42:39.118000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-11 04:42:39.125536: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-11 04:42:40.544834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Currently logged in as: ljcpro (alps-lab-sok). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /home/jkl6486/sok-llm-watermark/wandb/run-20240111_044245-6vjw30gh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gen-c4-xuandong23b-llama-temp1.3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/alps-lab-sok/lm-watermarking
wandb: üöÄ View run at https://wandb.ai/alps-lab-sok/lm-watermarking/runs/6vjw30gh
No limit_indices specified, pulling all examples from the dataset.
Output dir for this run: runs/xuandong23b/c4/llama/gen-1.3
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.67s/it]
  0%|          | 0/1000 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Traceback (most recent call last):
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/generation_pipeline.py", line 871, in <module>
    main(args)
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/generation_pipeline.py", line 404, in main
    ex = next(ds_iterator)
         ^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/datasets/iterable_dataset.py", line 981, in __iter__
    for key, example in ex_iterable:
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/datasets/iterable_dataset.py", line 477, in __iter__
    transformed_batch.update(self.function(*function_args, **self.fn_kwargs))
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/sok-llm-watermark/watermark_reliability_release/utils/generation.py", line 485, in generate
    output_without_watermark = generate_without_watermark(input_ids=input_ids)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/transformers/generation/utils.py", line 1764, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/home/jkl6486/miniconda3/envs/hermes/lib/python3.11/site-packages/transformers/generation/utils.py", line 2897, in sample
    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: probability tensor contains either `inf`, `nan` or element < 0
wandb: üöÄ View run gen-c4-xuandong23b-llama-temp1.3 at: https://wandb.ai/alps-lab-sok/lm-watermarking/runs/6vjw30gh
wandb: Ô∏è‚ö° View job at https://wandb.ai/alps-lab-sok/lm-watermarking/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMzQ2NTIxNg==/version_details/v38
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240111_044245-6vjw30gh/logs
2024-01-11 04:43:26.856364: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-11 04:43:26.905068: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-01-11 04:43:26.905132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-01-11 04:43:26.906415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-11 04:43:26.914388: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-11 04:43:28.366065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Currently logged in as: ljcpro (alps-lab-sok). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /home/jkl6486/sok-llm-watermark/wandb/run-20240111_044333-ki5koucn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gen-c4-xuandong23b-opt-temp1.3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/alps-lab-sok/lm-watermarking
wandb: üöÄ View run at https://wandb.ai/alps-lab-sok/lm-watermarking/runs/ki5koucn
No limit_indices specified, pulling all examples from the dataset.
Output dir for this run: runs/xuandong23b/c4/opt/gen-1.3
  0%|          | 0/1000 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/1000 [00:49<13:52:19, 49.99s/it]  0%|          | 5/1000 [01:27<4:14:50, 15.37s/it]   1%|          | 9/1000 [01:53<2:54:21, 10.56s/it]  1%|‚ñè         | 13/1000 [02:22<2:30:21,  9.14s/it]  2%|‚ñè         | 17/1000 [03:04<2:37:29,  9.61s/it]  2%|‚ñè         | 21/1000 [03:42<2:36:15,  9.58s/it]  2%|‚ñé         | 25/1000 [04:20<2:34:58,  9.54s/it]  3%|‚ñé         | 29/1000 [05:02<2:39:43,  9.87s/it]  3%|‚ñé         | 33/1000 [05:46<2:44:20, 10.20s/it]  4%|‚ñé         | 37/1000 [06:21<2:37:14,  9.80s/it]  4%|‚ñç         | 41/1000 [06:47<2:20:14,  8.77s/it]  4%|‚ñç         | 45/1000 [07:27<2:24:48,  9.10s/it]  5%|‚ñç         | 49/1000 [08:09<2:31:48,  9.58s/it]  5%|‚ñå         | 53/1000 [08:53<2:37:23,  9.97s/it]  6%|‚ñå         | 57/1000 [09:32<2:35:31,  9.90s/it]  6%|‚ñå         | 61/1000 [10:09<2:31:50,  9.70s/it]  6%|‚ñã         | 65/1000 [10:40<2:22:08,  9.12s/it]  7%|‚ñã         | 69/1000 [11:03<2:06:03,  8.12s/it]  7%|‚ñã         | 73/1000 [11:39<2:09:43,  8.40s/it]  8%|‚ñä         | 77/1000 [11:59<1:52:54,  7.34s/it]  8%|‚ñä         | 81/1000 [12:17<1:40:17,  6.55s/it]  8%|‚ñä         | 85/1000 [12:46<1:42:34,  6.73s/it]  9%|‚ñâ         | 89/1000 [13:25<1:55:56,  7.64s/it]  9%|‚ñâ         | 93/1000 [14:16<2:18:35,  9.17s/it] 10%|‚ñâ         | 97/1000 [14:44<2:07:57,  8.50s/it] 10%|‚ñà         | 101/1000 [15:34<2:25:47,  9.73s/it] 10%|‚ñà         | 105/1000 [16:16<2:27:52,  9.91s/it] 11%|‚ñà         | 109/1000 [16:53<2:24:40,  9.74s/it] 11%|‚ñà‚ñè        | 113/1000 [17:32<2:23:49,  9.73s/it] 12%|‚ñà‚ñè        | 117/1000 [18:22<2:35:30, 10.57s/it] 12%|‚ñà‚ñè        | 121/1000 [18:53<2:22:11,  9.71s/it] 12%|‚ñà‚ñé        | 125/1000 [19:14<2:02:33,  8.40s/it] 13%|‚ñà‚ñé        | 129/1000 [19:56<2:10:37,  9.00s/it] 13%|‚ñà‚ñé        | 133/1000 [20:36<2:14:23,  9.30s/it] 14%|‚ñà‚ñé        | 137/1000 [21:23<2:24:41, 10.06s/it] 14%|‚ñà‚ñç        | 141/1000 [21:59<2:19:19,  9.73s/it] 14%|‚ñà‚ñç        | 145/1000 [22:36<2:16:59,  9.61s/it] 15%|‚ñà‚ñç        | 149/1000 [23:25<2:27:25, 10.39s/it] 15%|‚ñà‚ñå        | 153/1000 [24:09<2:28:59, 10.55s/it] 16%|‚ñà‚ñå        | 157/1000 [25:00<2:37:56, 11.24s/it] 16%|‚ñà‚ñå        | 161/1000 [25:35<2:26:39, 10.49s/it] 16%|‚ñà‚ñã        | 165/1000 [26:30<2:39:22, 11.45s/it] 17%|‚ñà‚ñã        | 169/1000 [27:08<2:30:38, 10.88s/it] 17%|‚ñà‚ñã        | 173/1000 [27:43<2:21:27, 10.26s/it] 18%|‚ñà‚ñä        | 177/1000 [28:19<2:15:26,  9.87s/it] 18%|‚ñà‚ñä        | 181/1000 [29:04<2:19:51, 10.25s/it] 18%|‚ñà‚ñä        | 185/1000 [29:43<2:17:03, 10.09s/it] 19%|‚ñà‚ñâ        | 189/1000 [30:26<2:19:35, 10.33s/it] 19%|‚ñà‚ñâ        | 193/1000 [31:15<2:26:39, 10.90s/it] 20%|‚ñà‚ñâ        | 197/1000 [31:56<2:23:35, 10.73s/it] 20%|‚ñà‚ñà        | 201/1000 [32:19<2:02:18,  9.18s/it] 20%|‚ñà‚ñà        | 205/1000 [32:52<1:58:43,  8.96s/it] 21%|‚ñà‚ñà        | 209/1000 [33:39<2:08:50,  9.77s/it] 21%|‚ñà‚ñà‚ñè       | 213/1000 [34:01<1:51:12,  8.48s/it] 22%|‚ñà‚ñà‚ñè       | 217/1000 [34:16<1:32:26,  7.08s/it] 22%|‚ñà‚ñà‚ñè       | 221/1000 [34:47<1:34:26,  7.27s/it] 22%|‚ñà‚ñà‚ñé       | 225/1000 [35:21<1:38:46,  7.65s/it] 23%|‚ñà‚ñà‚ñé       | 229/1000 [36:08<1:54:16,  8.89s/it] 23%|‚ñà‚ñà‚ñé       | 233/1000 [36:48<1:57:50,  9.22s/it] 24%|‚ñà‚ñà‚ñé       | 237/1000 [37:39<2:10:26, 10.26s/it] 24%|‚ñà‚ñà‚ñç       | 241/1000 [38:28<2:16:53, 10.82s/it] 24%|‚ñà‚ñà‚ñç       | 245/1000 [39:13<2:18:40, 11.02s/it] 25%|‚ñà‚ñà‚ñç       | 249/1000 [39:55<2:15:37, 10.83s/it] 25%|‚ñà‚ñà‚ñå       | 253/1000 [40:30<2:07:23, 10.23s/it] 26%|‚ñà‚ñà‚ñå       | 257/1000 [41:01<1:57:21,  9.48s/it] 26%|‚ñà‚ñà‚ñå       | 261/1000 [41:33<1:51:19,  9.04s/it] 26%|‚ñà‚ñà‚ñã       | 265/1000 [42:14<1:54:35,  9.35s/it] 27%|‚ñà‚ñà‚ñã       | 269/1000 [43:08<2:09:05, 10.60s/it] 27%|‚ñà‚ñà‚ñã       | 273/1000 [43:55<2:12:54, 10.97s/it] 28%|‚ñà‚ñà‚ñä       | 277/1000 [44:41<2:14:15, 11.14s/it] 28%|‚ñà‚ñà‚ñä       | 281/1000 [45:17<2:05:59, 10.51s/it] 28%|‚ñà‚ñà‚ñä       | 285/1000 [46:02<2:07:37, 10.71s/it] 29%|‚ñà‚ñà‚ñâ       | 289/1000 [46:51<2:12:13, 11.16s/it] 29%|‚ñà‚ñà‚ñâ       | 293/1000 [47:28<2:04:27, 10.56s/it] 30%|‚ñà‚ñà‚ñâ       | 297/1000 [48:03<1:57:51, 10.06s/it] 30%|‚ñà‚ñà‚ñà       | 301/1000 [48:42<1:56:03,  9.96s/it] 30%|‚ñà‚ñà‚ñà       | 305/1000 [49:01<1:37:01,  8.38s/it] 31%|‚ñà‚ñà‚ñà       | 309/1000 [49:20<1:24:27,  7.33s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 313/1000 [50:00<1:32:56,  8.12s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 317/1000 [50:35<1:34:13,  8.28s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 321/1000 [51:13<1:38:00,  8.66s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 325/1000 [51:49<1:38:55,  8.79s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 329/1000 [52:29<1:41:45,  9.10s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 333/1000 [53:06<1:41:41,  9.15s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 337/1000 [53:45<1:43:35,  9.37s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 341/1000 [54:27<1:46:46,  9.72s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 345/1000 [55:04<1:44:31,  9.57s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 349/1000 [55:36<1:38:51,  9.11s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 353/1000 [56:16<1:40:34,  9.33s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 357/1000 [56:50<1:37:34,  9.10s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 361/1000 [57:28<1:38:26,  9.24s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 365/1000 [58:17<1:47:16, 10.14s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 369/1000 [58:59<1:47:41, 10.24s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 373/1000 [59:44<1:50:18, 10.56s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 377/1000 [1:00:23<1:46:59, 10.30s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 381/1000 [1:01:07<1:48:16, 10.50s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 385/1000 [1:01:45<1:44:17, 10.18s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 389/1000 [1:02:31<1:47:54, 10.60s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 393/1000 [1:03:12<1:45:57, 10.47s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 397/1000 [1:03:40<1:35:13,  9.47s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 401/1000 [1:04:08<1:26:40,  8.68s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 405/1000 [1:04:24<1:12:18,  7.29s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 409/1000 [1:05:06<1:21:39,  8.29s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 413/1000 [1:05:41<1:22:27,  8.43s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 417/1000 [1:06:16<1:22:43,  8.51s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 421/1000 [1:07:00<1:29:30,  9.28s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 425/1000 [1:07:34<1:26:15,  9.00s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 429/1000 [1:08:14<1:28:43,  9.32s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 433/1000 [1:09:04<1:37:20, 10.30s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 437/1000 [1:09:48<1:38:16, 10.47s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 441/1000 [1:10:22<1:31:55,  9.87s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 445/1000 [1:10:45<1:20:00,  8.65s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 449/1000 [1:11:05<1:09:14,  7.54s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 453/1000 [1:11:27<1:03:06,  6.92s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 457/1000 [1:11:47<57:47,  6.39s/it]   46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 461/1000 [1:12:14<58:02,  6.46s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 465/1000 [1:12:40<57:57,  6.50s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 469/1000 [1:13:27<1:11:24,  8.07s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 473/1000 [1:14:17<1:22:40,  9.41s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 477/1000 [1:15:03<1:27:32, 10.04s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 481/1000 [1:15:46<1:28:14, 10.20s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 485/1000 [1:16:28<1:28:25, 10.30s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 489/1000 [1:17:09<1:27:58, 10.33s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 493/1000 [1:18:01<1:33:34, 11.07s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 497/1000 [1:18:50<1:35:45, 11.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 501/1000 [1:19:39<1:37:33, 11.73s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 505/1000 [1:20:21<1:33:41, 11.36s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 509/1000 [1:20:59<1:28:00, 10.75s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 513/1000 [1:21:09<1:07:10,  8.28s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 517/1000 [1:21:23<55:22,  6.88s/it]   52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 521/1000 [1:21:40<48:18,  6.05s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 525/1000 [1:22:14<53:49,  6.80s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 529/1000 [1:23:05<1:07:14,  8.57s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 533/1000 [1:23:43<1:08:57,  8.86s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 537/1000 [1:24:23<1:11:14,  9.23s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 541/1000 [1:25:00<1:10:39,  9.24s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 545/1000 [1:25:44<1:13:53,  9.74s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 549/1000 [1:26:31<1:17:38, 10.33s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 553/1000 [1:27:12<1:16:51, 10.32s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 557/1000 [1:28:00<1:19:56, 10.83s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 561/1000 [1:28:43<1:19:02, 10.80s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 565/1000 [1:29:14<1:12:01,  9.93s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 569/1000 [1:29:52<1:10:03,  9.75s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 573/1000 [1:30:34<1:10:53,  9.96s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 577/1000 [1:31:12<1:09:33,  9.87s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 581/1000 [1:31:55<1:10:33, 10.10s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 585/1000 [1:32:29<1:06:34,  9.62s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 589/1000 [1:33:08<1:06:30,  9.71s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 593/1000 [1:33:49<1:06:36,  9.82s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 597/1000 [1:34:23<1:03:34,  9.47s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 601/1000 [1:35:01<1:02:58,  9.47s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 605/1000 [1:35:39<1:02:18,  9.46s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 609/1000 [1:36:07<56:38,  8.69s/it]   61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 613/1000 [1:36:21<46:05,  7.15s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 617/1000 [1:36:54<47:45,  7.48s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 621/1000 [1:37:35<52:40,  8.34s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 625/1000 [1:38:06<50:43,  8.11s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 629/1000 [1:38:52<56:33,  9.15s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 633/1000 [1:39:35<59:04,  9.66s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 637/1000 [1:40:09<56:05,  9.27s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 641/1000 [1:40:40<52:52,  8.84s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 645/1000 [1:41:05<47:44,  8.07s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 649/1000 [1:41:43<49:30,  8.46s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 653/1000 [1:42:32<55:50,  9.65s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 657/1000 [1:43:23<1:00:26, 10.57s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 661/1000 [1:44:10<1:01:30, 10.89s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 665/1000 [1:44:58<1:02:49, 11.25s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 669/1000 [1:45:35<58:41, 10.64s/it]   67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 673/1000 [1:46:13<56:03, 10.28s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 677/1000 [1:46:57<56:48, 10.55s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 681/1000 [1:47:39<55:44, 10.49s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 685/1000 [1:48:09<50:27,  9.61s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 689/1000 [1:48:52<51:41,  9.97s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 693/1000 [1:49:29<49:44,  9.72s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 697/1000 [1:49:58<45:25,  9.00s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 701/1000 [1:50:43<48:02,  9.64s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 705/1000 [1:51:22<47:48,  9.72s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 709/1000 [1:51:43<40:40,  8.39s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 713/1000 [1:51:58<33:28,  7.00s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 717/1000 [1:52:36<36:17,  7.70s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 721/1000 [1:53:16<38:56,  8.38s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 725/1000 [1:53:46<37:11,  8.11s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 729/1000 [1:54:11<34:12,  7.57s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 733/1000 [1:54:50<36:32,  8.21s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 737/1000 [1:55:35<40:02,  9.13s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 741/1000 [1:56:21<42:36,  9.87s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 745/1000 [1:57:05<43:17, 10.19s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 749/1000 [1:57:48<43:30, 10.40s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 753/1000 [1:58:28<42:03, 10.22s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 757/1000 [1:59:21<45:15, 11.18s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 761/1000 [2:00:16<47:38, 11.96s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 765/1000 [2:00:59<45:20, 11.57s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 769/1000 [2:01:45<44:25, 11.54s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 773/1000 [2:02:21<40:46, 10.78s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 777/1000 [2:03:03<39:49, 10.72s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 781/1000 [2:03:44<38:31, 10.55s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 785/1000 [2:04:21<36:32, 10.20s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 789/1000 [2:04:59<35:05,  9.98s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 793/1000 [2:05:46<36:14, 10.51s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 797/1000 [2:06:31<36:10, 10.69s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 801/1000 [2:07:04<33:10, 10.00s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 805/1000 [2:07:14<25:07,  7.73s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 809/1000 [2:07:26<20:06,  6.31s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 813/1000 [2:08:19<26:07,  8.38s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 817/1000 [2:08:53<25:35,  8.39s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 821/1000 [2:09:35<27:03,  9.07s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 825/1000 [2:10:14<27:07,  9.30s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 829/1000 [2:11:08<29:58, 10.52s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 833/1000 [2:11:30<25:04,  9.01s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 837/1000 [2:11:52<21:41,  7.99s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 841/1000 [2:12:17<19:44,  7.45s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 845/1000 [2:12:38<17:30,  6.78s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 849/1000 [2:13:01<16:21,  6.50s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 853/1000 [2:13:26<15:37,  6.38s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 857/1000 [2:14:06<17:55,  7.52s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 861/1000 [2:14:51<20:00,  8.64s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 865/1000 [2:15:41<22:02,  9.80s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 869/1000 [2:16:19<21:09,  9.69s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 873/1000 [2:16:55<19:59,  9.44s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 877/1000 [2:17:28<18:40,  9.11s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 881/1000 [2:18:03<17:53,  9.02s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 885/1000 [2:18:38<17:08,  8.95s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 889/1000 [2:19:08<15:43,  8.50s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 893/1000 [2:19:48<16:00,  8.98s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 897/1000 [2:20:23<15:13,  8.87s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 901/1000 [2:20:57<14:27,  8.77s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 905/1000 [2:21:26<13:12,  8.34s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 909/1000 [2:22:05<13:15,  8.74s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 913/1000 [2:22:48<13:34,  9.36s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 917/1000 [2:23:39<14:21, 10.37s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 921/1000 [2:24:28<14:22, 10.91s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 925/1000 [2:24:45<11:05,  8.88s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 929/1000 [2:25:22<10:41,  9.03s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 933/1000 [2:26:11<11:07,  9.96s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 937/1000 [2:26:57<10:56, 10.41s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 941/1000 [2:27:40<10:24, 10.58s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 945/1000 [2:28:18<09:21, 10.20s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 949/1000 [2:29:00<08:47, 10.35s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 953/1000 [2:29:43<08:10, 10.44s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 957/1000 [2:30:23<07:23, 10.31s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 961/1000 [2:31:14<07:10, 11.03s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 965/1000 [2:31:55<06:16, 10.77s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 969/1000 [2:32:35<05:28, 10.59s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 973/1000 [2:33:15<04:40, 10.40s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 977/1000 [2:33:56<03:58, 10.35s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 981/1000 [2:34:32<03:08,  9.91s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 985/1000 [2:35:14<02:31, 10.13s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 989/1000 [2:35:43<01:42,  9.29s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 993/1000 [2:36:23<01:06,  9.51s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 997/1000 [2:37:01<00:28,  9.46s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [2:37:01<00:00,  9.42s/it]


























































































































































































































































################################################################################ 
Generation output length check overhead was num rows processed=1000 for 1000 samples. Ratio: 1.0
Writing JSON lines at runs/xuandong23b/c4/opt/gen-1.3/gen_table.jsonl:   0%|          | 0/1000 [00:00<?, ?it/s]Writing JSON lines at runs/xuandong23b/c4/opt/gen-1.3/gen_table.jsonl: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 38987.40it/s]
wandb: - 0.008 MB of 0.008 MB uploadedwandb: \ 0.008 MB of 0.008 MB uploadedwandb: | 0.008 MB of 0.008 MB uploadedwandb: / 0.008 MB of 0.008 MB uploadedwandb: - 0.044 MB of 0.044 MB uploaded (0.008 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 17.6%             
wandb: 
wandb: Run history:
wandb: generation_overhead_ratio ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:  num_satisfactory_samples ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:            progress_ratio ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   total_generated_samples ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb: generation_overhead_ratio 0.999
wandb:  num_satisfactory_samples 1000
wandb:            progress_ratio 1.0
wandb:   total_generated_samples 1000
wandb: 
wandb: üöÄ View run gen-c4-xuandong23b-opt-temp1.3 at: https://wandb.ai/alps-lab-sok/lm-watermarking/runs/ki5koucn
wandb: Ô∏è‚ö° View job at https://wandb.ai/alps-lab-sok/lm-watermarking/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMzQ2NTIxNg==/version_details/v39
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240111_044333-ki5koucn/logs
