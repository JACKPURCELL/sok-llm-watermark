from __future__ import annotations
import torch
from transformers import LogitsProcessor

import numpy as np



# {

#     "version": "0.2.0",
#     "configurations": [
#         {
#             "name": "Python: main",
#             "type": "python",
#             "request": "launch",
#             "program": "main.py",
#             "console": "integratedTerminal",
#             "justMyCode": true,
#             "env": {"CUDA_VISIBLE_DEVICES":"1"},
#             "args": ["--watermark","rohit23"]
#         }
#     ]
# }



        
class sample_WatermarkLogitsProcessor(LogitsProcessor):
    def __init__(self, vocab_size, key=42):
        #Please use the rng algorithim like this
        self.rng = np.random.default_rng(key)
        #rng use sample
        sample_random = torch.from_numpy(self.rng.random((self.vocab_size),np.float32)).cuda()

    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:
        #Note that the score has not been softmaxed
        probs = torch.nn.functional.softmax(scores, dim=-1) 
    ######################################################################
    # Add your code here
    ######################################################################
    # add the inject watermark algorithim here
    ######################################################################           
        return probs


class sample_WatermarkDetector:
    def __init__(self,  vocab_size, tokenizer, n=256, key=42):
        self.n = n
        self.rng = np.random.default_rng(key)
        self.vocab_size = vocab_size
        self.min_prefix_len = 1
        self.tokenizer=tokenizer
        # you need to define the z_threshold here
        self.z_threshold = 4.0
    
  
    def detect(self,text,n_runs=100):
        tokenized_text = self.tokenizer(text, return_tensors="pt", add_special_tokens=False)["input_ids"][0].cuda()
        if tokenized_text[0] == self.tokenizer.bos_token_id:
            tokenized_text = tokenized_text[1:]
            
        output_dict = {}
        
        k = len(tokenized_text)
        output_dict["num_tokens_scored"] = k
        
        ######################################################################
        # Add your code here
        ######################################################################
        # add the detect watermark algorithim here
        ######################################################################     
        
        #Add the output infor into the output_dict
        # output_dict["z_score"] = z_score
        # output_dict["num_green_tokens"] = num_green_tokens
        
        # output_dict["prediction"] = True
        return output_dict

      

       


