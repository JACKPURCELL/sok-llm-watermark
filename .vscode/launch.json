{

    "version": "0.2.0",
    "configurations": [


        {
            "name": "inject",
            "type": "python",
            "request": "launch",
            "program": "main.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "env": {"CUDA_VISIBLE_DEVICES":"1,2,3"},
            "args": ["--watermark","lean23"]
        },
        {
            "name": "attack",
            "type": "python",
            "request": "launch",
            "program": "main.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "env": {"CUDA_VISIBLE_DEVICES":"1,2"},
            "args": ["--watermark","john23","--attack","dipper"]
        },
        {
            "name": "new_inject",
            "type": "python",
            "request": "launch",
            "program": "watermark_reliability_release/generation_pipeline.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "env": {"CUDA_VISIBLE_DEVICES":"0,1,2,3"},
            "args": ["--watermark","lean23","--dataset_name","hc3","--run_name","test-gen-lean23","--model_name_or_path","meta-llama/Llama-2-7b-chat-hf","--min_generations","1"]
        },
    ]
}